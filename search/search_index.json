{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"<p>The UNSW Workflow Platform implements commonly used pipelines for the analysis of next-generation sequencing data on the UNSW High-Performance Computing (HPC) Infrastructure.</p> Overview of Workflows for Sequencing Data Analysis <p>Workflows are data analysis pipelines implemented using a workflow manager. In general, workflow managers simplify the use of complex pipelines composed of multiple software tools by handling software installation and versions and optimizing the use of computing resources. Implementing pipelines as workflows on the UNSW HPC has the following advantages:</p> <ol> <li> <p>Shareability Pipelines implemented as workflows are easy to share and use by any UNSW research group since the software installation and version management are handled by the workflow manager.</p> </li> <li> <p>Reproducibility Workflow managers were developed to address the challenge of reproducibility in bioinformatics. Analyzing data in a consistent manner with a standardized well documented pipeline.</p> </li> <li> <p>Productivity Increased productivity is achieved by linking the data analysis pipelines to the Ramaciotti Centre data production. In addition, the bioinformatics community is increasingly producing best-practice data analysis pipelines that are easy to adopt in a workflow format, facilitating working with new data types.</p> </li> </ol> <p>For more details on the goals and advantages of bioinformatics workflows see:</p> <p>Wratten et al. Reproducible, scalable, and shareable analysis pipelines with bioinformatics workflow managers. Nature Methods 2021.</p>"},{"location":"#overview-of-the-unsw-seq-flow-platform","title":"Overview of the UNSW Seq-flow platform","text":"<p>The analysis of next-generation sequencing (NGS) data, regardless of its type, has two main stages: (i) alignment of sequencing reads to the reference genome, feature quantification, and quality control assessments and  (ii) extracting biological information from the quantified features by differential expression analyses or co-expression networks (RNA-seq), differential accessibility (ATAC-seq), identification of differentially methylated regions (BS-seq) etc.</p> <p>The Seq-flow Platform is focused on implementing pipelines for the first stage of NGS data analysis which is computationally intensive, requires larger storage space and more advanced coding skills, and can be easily automated. It is not focused on the second stage, which requires fine-tuning of data analysis in a project-specific manner and can often be carried out on a personal laptop with basic bioinformatics skills (eg. R/Bioconductor). We do however suggest good options for some common downstream analyses for students with limited coding experience.</p> <p> </p> Seq-flow is implemented as both a Web User Interface and a Command Line Interface using the workflow manager Nextflow. <p>Seq-flow supports input sequencing data:</p> <ul> <li>stored on UNSW Katana servers.</li> <li>automatically downloaded on Katana from a Ramaciotti Sequencing run.</li> <li>automatically downloaded on Katana from NCBI SRA.</li> </ul> <p>Seq-flow allows users to run any of the large collection of Nextflow Core pipelines.</p> <p>Nextflow Core (nf-core) is an active bioinformatics community developing open-source pipelines based on NextFlow that aim to implement the best practices in the field.  For more details on nf-core pipelines see: </p> <p>Ewels et al. The nf-core framework for community-curated bioinformatics pipelines. Nature Biotechnology 2022.</p> <p>The nf-core pipelines fall into two categories in terms of their use in Seq-flow:</p> <ol> <li>Pre-tested pipelines, which we have extensively tested and documented. These include the bulk RNA-seq pipeline (for any organism) and scRNA-seq.</li> <li>User-adopted, which refers to any nf-core pipeline not yet tested by the Seq-flow team. We can offer support for UNSW users interested in using and testing additional nf-core pipelines, to expand the list of pre-tested pipelines.</li> </ol> <p>Users can also deploy custom NextFlow workflows in Seq-flow.</p> Getting Started User Guides Support"},{"location":"overview/","title":"Overview","text":"<p>The UNSW Workflow Platform implements commonly used pipelines for the analysis of next-generation sequencing data on the UNSW High-Performance Computing (HPC) Infrastructure. </p>"},{"location":"overview/#why-are-workflows-useful","title":"Why are Workflows Useful?","text":"<p>Workflows are data analysis pipelines implemented using a workflow manager. In general, workflow managers simplify the use of complex pipelines composed of multiple software tools by handling software installation and versions and optimizing the use of computing resources. Implementing pipelines as workflows on the UNSW HPC has the following advantages:</p> <ol> <li>Shareability Pipelines implemented as workflows are easy to share and use by any UNSW research group since the software installation and version management are handled by the workflow manager.</li> <li>Reproducibility Workflow managers were developed to address the challenge of reproducibility in bioinformatics. Analyzing data in a consistent manner with a standardized well documented pipeline. </li> <li>Productivity Increased productivity is achieved by linking the data analysis pipelines to the Ramaciotti Centre data production. In addition, the bioinformatics community is increasingly producing best-practice data analysis pipelines that are easy to adopt in a workflow format, facilitating working with new data types.</li> </ol> <p>For more details on the goals and advantages of bioinformatics workflows see: Wratten et al. Reproducible, scalable, and shareable analysis pipelines with bioinformatics workflow managers. Nature Methods 2021.</p>"},{"location":"support/","title":"Support","text":""},{"location":"support/#contact-the-research-technology-services-team","title":"Contact the Research Technology Services team","text":"<p>For Katana issues including: functional issues, software installation, reference data sets, general questions -  email the IT Service Centre, including the word Katana in the subject line.</p> <p>Info</p> <p>This is the best and primary way to get help from UNSW Research Technology Services beyond this document. You must use your UNSW email address or your zID. Without this information, we have no idea who you might be.</p> <p>When writing your email, please include a clear and detailed description of the issue experienced, including error messages and node name. Something like \"It doesn't work\" doesn't help us help you! If at all possible, include the steps someone else needs to do to reproduce the problem, the job identifier, the date and time of your problem and on which Katana node it occurred, the script filename and the directory you were running from.</p> <p>Example of a bad request     i'm trying to do some work on katana, but it seems that the server is slow or not responsive at times. i'm logged in from inside unsw today, so working from home shouldn't be the issue.</p> <p>Example of a great request     When I tried to run Sentaurus TCAD today (2020-05-01) on Katana I got this error message regardless of structures I wanted to simulate:</p> <pre><code>\u201cJob failed\nError: Child process with pid '116643' got the signal 'SIGSEGV' (segmentation violation)\njob exits with status 1\u201d\n\nMy job ran on k052 with jobid 300000, my zID is z2134567\n</code></pre> <p>For face to face support: Drop-In Hour Wednesdays, 1pm.</p> <p>For questions about research data at UNSW - on storage, movement or Data Management Plans, please email the Research Data Team. If you specifically wish to increase Katana storage allocations, please email the IT Service Centre - note that such increases are not automatic.</p>"},{"location":"support/#katana-terms-of-use","title":"Katana Terms of Use","text":"<p>Any use of Katana is covered by the Conditions of Use - UNSW ICT Resources. </p> <p>Warning</p> <p>Katana is not suitable for highly sensitive data. You should use the UNSW Data Classification scheme to classify your data and learn about managing your research data by visiting the Research Data Management Hub.</p>"},{"location":"getting_started/choosing_interface/","title":"Choosing an Interface","text":"<p>All interfaces are based on Nextflow. Nextflow is a workflow language and executor for reproducible, containerized bioinformatics. The following serves as a quick, comparative reference for different ways you can run the same workflow, including ones you write yourself. See e.g. our Bulk RNA-Seq Guide or the official nf-core site for more in-depth parameter information for any examples.</p> <p> </p>"},{"location":"getting_started/choosing_interface/#feature-comparison","title":"Feature Comparison","text":"<p>For a practical overview of each method, see the launching comparison</p> Genomic Workflow Utility Nextflow Tower Command-line Fast access of reads generated at Ramaciotti Parameter input UI UI nf-params.json Remote monitoring Intermediate Advanced Initial configuration None Recommended: useGenomic Workflow Utility sidebar module load"},{"location":"getting_started/choosing_interface/#launching-comparison","title":"Launching Comparison","text":"<p>Nextflow is a workflow language and executor for reproducible, containerized bioinformatics. The following serves as a quick, comparative reference for different ways you can run the same workflow, including ones you write yourself. See e.g. our Bulk RNA-Seq Guide or the official nf-core site for more in-depth parameter information for any examples.</p> <p>Tip</p> <p>Due to Nextflow's intermediate file size requirements, we offer <code>/srv/scratch/genomicwf</code> for all BABS users with the limitation that files are deleted irreversibly after 3 days of not being read. Within this time-frame, you can <code>-resume</code> quickly with modified parameters. If lab scratch is preferred, we encourage the regular use of <code>nextflow clean</code>.</p> <p>New to Katana? You should review the Katana Guide before using any of the following methods.</p> <p>Platform</p> Katana OnDemandCommand-LineNextflow Tower <p>With a few clicks, you can run highly maintained, peer-reviewed nf-core community workflows on Katana OnDemand using a graphical user interface, directly on reads from Ramaciotti.</p> <ol> <li>Access the utility here. You must be at UNSW, or be logged in via VPN.</li> </ol> <p> Demonstrating initial steps of RNA-Seq </p> <ol> <li>(Optional) To uninstall, delete ~/ondemand/data/workflows_beta_4, and any datasets/runs you created</li> </ol> <p>The following instructions can be applied for community workflows or your own:</p> <ol> <li> <p>Connect via ssh     <pre><code>ssh &lt;zid&gt;@kdm.restech.unsw.edu.au # (1)!\n</code></pre></p> <ol> <li>It's best to use the Katana Data Mover node especially for step 3.</li> </ol> </li> <li> <p>Create and enter a new project folder     <pre><code>mkdir -p /srv/scratch/genomicwf/$USER/myproject &amp;&amp; cd $_  # (1)!\ngit clone https://github.com/WalshKieran/katana-rnaseq-start.git . # (2)!\n</code></pre></p> <ol> <li>Files stored in the \"genomicwf\" scratch are deleted if unused for 3 days. Nextflow working directories can exceed 1TB, but you may wish to try different parameters without recomputing everything within this timeframe.</li> <li>This copies a PBS batch template into your project folder. It will fail if there are any files already present.</li> </ol> </li> <li> <p>(Optional) Download your data from Ramaciotti and create samplesheet:     <pre><code>wget -qO- https://mydata.ramaciotti...MYDATA1234.tar | tar xvz -C ./mydata1234 # (1)!\nwget https://raw.githubusercontent.com/nf-core/rnaseq/master/bin/fastq_dir_to_samplesheet.py\npython3 fastq_dir_to_samplesheet.py --recursive ./mydata1234 ./samplesheet.csv\n</code></pre></p> <ol> <li>Follow the instructions from Ramaciotti - if access is via BaseSpace or a non-tar share link, you can use the \"Katana OnDemand\" utility to download.</li> </ol> </li> <li> <p>Launch and monitor     <pre><code>qsub run.pbs\nqstat -u $USER\ntail .nextflow.log\n</code></pre></p> </li> <li> <p>(Optional) Stop your job     <pre><code>qsig &lt;ID returned from qsub&gt; # (1)!\n</code></pre></p> <ol> <li>Why not qdel? When exiting, Nextflow waits for all child jobs to exit - this can take more time than qdel allows.</li> </ol> </li> </ol> <p>Nextflow Tower is a more advanced interface for launching and monitoring Nextflow workflows, but you will need to move data on and off Katana yourself using the Katana Data Mover.</p> <p>Bug</p> <p>Tower is still slightly incompatible with Katana as of June 20, 2023.</p> <p>One-off setup:</p> <ol> <li>Create a Tower account at https://tower.nf.</li> <li>Navigate to https://tower.nf/tokens, create and copy an access token.</li> <li>Paste your token into the \"Katana OnDemand\" workflow utility sidebar to automatically add Katana credentials/compute and even nf-core community workflows to your Tower personal workspace.</li> </ol> <p>We currently do not support group workspaces, as sharing login credentials is against the Katana usage policy.</p>"},{"location":"getting_started/choosing_interface/#resource-optimization-comparison-advanced","title":"Resource Optimization Comparison (Advanced)","text":"<p>The default allocations for generalized Nextflow workflows are extremely generous for most datasets - this may negatively impact your queue priority and run duration. If your input files are reasonably similar, you should consider configuring each process based on measurements.</p> <p>Optimization</p> Katana OnDemandCommand-LineNextflow Tower <p>See video in Launching a Workflow - the graphical interface interactively encourages the process described in \"Command-Line\".</p> <p>Below is an illustration of how to run nf-core/rnaseq without previous similar runs (e.g. similar or greater read depth). This is not a substitute for reading the nf-optimizer documentation/drawbacks carefully.</p> <ol> <li> <p>Limit the samples in your samplesheet, or by other means <pre><code>head -n 5 samplesheet.csv &gt; samplesheet_4.csv\n</code></pre></p> </li> <li> <p>Run Nextflow on limited samples <pre><code>export NXF_ENABLE_CACHE_INVALIDATION_ON_TASK_DIRECTIVE_CHANGE=false\nnextflow run ... --input samplesheet_4.csv\n</code></pre></p> </li> <li> <p>Generate resources.config (limited to ~120GB, 12 hours) <pre><code>nf-optimizer -m 500 120000 -t 300 43200 -o resources.config .\n</code></pre></p> </li> <li> <p>Run Nextflow on all samples <pre><code>export NXF_ENABLE_CACHE_INVALIDATION_ON_TASK_DIRECTIVE_CHANGE=false\nnextflow run ... --input samplesheet.csv -c resources.config -resume\n</code></pre></p> </li> </ol> <p>Nextflow Tower supports optimization based on a specific previous run. Click on a run in your history, navigate to \"Optimization Available\", and copy the configuration.</p> <p> Nextflow Tower built in optimization </p>"},{"location":"getting_started/first_steps/","title":"First Steps","text":"<p>To get started with the UNSW Workflow Platform, you will need the following:</p>"},{"location":"getting_started/first_steps/#1-katana-account","title":"1. Katana Account","text":"<p>You will need an account on the Katana servers and some basic ability to use Katana.</p>"},{"location":"getting_started/first_steps/#obtaining-a-katana-account","title":"Obtaining a Katana Account","text":"<p>To apply for an account you can send an email to the UNSW IT Service Centre giving your zID, your role within UNSW and the name of your supervisor.</p> <p>If your lab/group has a dedicated scratch space, they can contact us to grant you access to this shared space. This can be useful if your data and results files exceed you personal account space.</p>"},{"location":"getting_started/first_steps/#using-katana-servers","title":"Using Katana Servers","text":"<p>See New to Katana? for a summary of what's needed to get started, or the full official documentation.</p>"},{"location":"getting_started/first_steps/#2-sequencing-data","title":"2. Sequencing Data","text":"<p>Sequencing data can be specified as either:</p> <ul> <li>A path to a directory on Katana (eg. /srv/scratch/zID/myProject/Data).</li> <li> <p>A link provided by the Ramaciotti Centre      If your sequencing data has been generated at the Ramaciotti Centre, you will receive a url for downloading the data, such as:      https://mydata.ramaciotti.unsw.edu.au/s/PiE96tn58FZAZbs/download/ProjectID.tar. You can provide this link in the nf-core pipeline, without downloading the data. </p> <p>You will need to provide the path to an existing directory on Katana, where the pipeline should download the data, eg. /srv/scratch/zID/myProject/Data.</p> </li> <li> <p>An NCBI SRA number     If your would like to analyze publicly available data from NCBI/SRA, you can provide the SRA project ID, such as SRPXXXX without downloading the data. Note that GEO Id (GSEXXX) numbers are not supported. </p> <p>You will need to provide the path to an existing directory on Katana, where the pipeline should download the data, eg. /srv/scratch/zID/myProject/Data.</p> </li> </ul>"},{"location":"getting_started/first_steps/#4-understand-the-pipeline","title":"4. Understand the pipeline","text":"<p>This includes understanding each of the software tools included in the pipeline, the parameters of each tool, and the expected output files. nf-core pipelines include extensive documentation (eg. nf-core RNA-seq). In addition, we strongly encourage you to spend some time reading the documentation of each software tool included in the pipeline.</p>"},{"location":"getting_started/first_steps/#new-to-katana","title":"New to Katana?","text":"<p>The UNSW on-premise HPC, Katana, is encouraged for Nextflow users and is a good entry-point for HPC in general. That being said, NCI Gadi also has official documentation for running Nextflow, and supports Nextflow Tower using the <code>Agent</code> method.</p> <p>Once you have covered the basics of Nextflow, it is trivial to run workflows using the <code>local</code> executor. This is especially true with prokaryotic genomes. In fact, aside from genome indexing, only a few steps in RNA-Seq consistently require over 16GB RAM for human reads. If you are new to HPC, we still think it's worth learning the basics so that:</p> <ol> <li>You can use the same documentation for any genome</li> <li>Runtime is not as dependent on number of samples</li> <li>It's much easier to receive technical support</li> </ol> <p>The following will be a subset of the official documentation, intended for biologists.</p>"},{"location":"getting_started/first_steps/#logging-in","title":"Logging In","text":"<p>Whether you connect via a file browser or a terminal, there are two addresses to remember: the login nodes, used to start jobs/monitor jobs, and the Katana data mover - &lt;zid&gt;@katana.unsw.edu.au and &lt;zid&gt;@kdm.restech.unsw.edu.au respectively.</p> <p>If you login via SSH to Katana, remaining space in your available storage locations will be listed. You may notice by default, your largest available folder is \"user scratch\" (/srv/scratch/&lt;zid&gt;) at 128GB. If your group has a shared scratch folder (often many terabytes in size), they can contact us for your account be granted access.</p>"},{"location":"getting_started/first_steps/#moving-data","title":"Moving Data","text":"<p>The most pertinent step in bioinformatics is copy e.g. .fastq.gz read files to Katana and copy the results back out. Consider downloading directly from the source when possible, as Katana's internet connection is likely many times faster than moving it through your own machine.</p> <p>To get started, you can connect FileZilla directly to the Katana data mover and access all your files described in storage locations.</p>"},{"location":"getting_started/first_steps/#checking-available-space","title":"Checking Available Space","text":"<p>While knowledge of storage location quotas is good when you don't have any existing files, it's important to continuously check remaining space when running large biological workflows that produce a lot of output. Relocating a failed Nextflow run to a different (larger) scratch is easy, but it will re-run every subtask unless a lot of care is taken. </p> <p>It is straightforward to use FileZilla to check available space. When you login via command-line, the first message will overview current usage (accurate to ~10 minutes) or you can run <code>df -H</code>.</p>"},{"location":"getting_started/first_steps/#katana-ondemand","title":"Katana OnDemand","text":"<p>You can run various GUI applications such as RStudio directly from your browser using Katana OnDemand. This includes RStudio and the Genomic Workflow Utility.</p>"},{"location":"getting_started/interfaces/cli/","title":"Command Line","text":""},{"location":"getting_started/interfaces/genomic_workflow_utility/","title":"Genomic Workflow Utility","text":""},{"location":"getting_started/interfaces/tower/","title":"Nextflow Tower","text":""},{"location":"guide/managing_resources/","title":"Managing Resources - Time/Memory/Space","text":""},{"location":"guide/nextflow/","title":"Nextflow","text":""},{"location":"guide/nextflow/#nextflow","title":"Nextflow","text":"<p>Nextflow is a workflow language and executor for reproducible, containerized bioinformatics. The following serves as a quick, comparative reference for different ways you can run the same workflow, including ones you write yourself. See e.g. our Bulk RNA-Seq Guide or the official nf-core site for more in-depth parameter information for any examples.</p> <p>Tip</p> <p>Due to Nextflow's intermediate file size requirements, we offer <code>/srv/scratch/genomicwf</code> for all BABS users with the limitation that files are deleted irreversibly after 3 days of not being read. Within this time-frame, you can <code>-resume</code> quickly with modified parameters. If lab scratch is preferred, we encourage the regular use of <code>nextflow clean</code>.</p>"},{"location":"guide/nextflow/#launching-comparison","title":"Launching Comparison","text":"<p>New to Katana? You should review the Katana Guide before using any of the following methods.</p> <p>Platform</p> Katana OnDemandCommand-LineNextflow Tower <p>With a few clicks, you can run highly maintained, peer-reviewed nf-core community workflows on Katana OnDemand using a graphical user interface, directly on reads from Ramaciotti.</p> <ol> <li>Access the utility here. You must be at UNSW, or be logged in via VPN.</li> </ol> <p> Demonstrating initial steps of RNA-Seq </p> <ol> <li>(Optional) To uninstall, delete ~/ondemand/data/workflows_beta_4, and any datasets/runs you created</li> </ol> <p>The following instructions can be applied for community workflows or your own:</p> <ol> <li> <p>Connect via ssh     <pre><code>ssh &lt;zid&gt;@kdm.restech.unsw.edu.au # (1)!\n</code></pre></p> <ol> <li>It's best to use the Katana Data Mover node especially for step 3.</li> </ol> </li> <li> <p>Create and enter a new project folder     <pre><code>mkdir -p /srv/scratch/genomicwf/$USER/myproject &amp;&amp; cd $_  # (1)!\ngit clone https://github.com/WalshKieran/katana-rnaseq-start.git . # (2)!\n</code></pre></p> <ol> <li>Files stored in the \"genomicwf\" scratch are deleted if unused for 3 days. Nextflow working directories can exceed 1TB, but you may wish to try different parameters without recomputing everything within this timeframe.</li> <li>This copies a PBS batch template into your project folder. It will fail if there are any files already present.</li> </ol> </li> <li> <p>(Optional) Download your data from Ramaciotti and create samplesheet:     <pre><code>wget -qO- https://mydata.ramaciotti...MYDATA1234.tar | tar xvz -C ./mydata1234 # (1)!\nwget https://raw.githubusercontent.com/nf-core/rnaseq/master/bin/fastq_dir_to_samplesheet.py\npython3 fastq_dir_to_samplesheet.py --recursive ./mydata1234 ./samplesheet.csv\n</code></pre></p> <ol> <li>Follow the instructions from Ramaciotti - if access is via BaseSpace or a non-tar share link, you can use the \"Katana OnDemand\" utility to download.</li> </ol> </li> <li> <p>Launch and monitor     <pre><code>qsub run.pbs\nqstat -u $USER\ntail .nextflow.log\n</code></pre></p> </li> <li> <p>(Optional) Stop your job     <pre><code>qsig &lt;ID returned from qsub&gt; # (1)!\n</code></pre></p> <ol> <li>Why not qdel? When exiting, Nextflow waits for all child jobs to exit - this can take more time than qdel allows.</li> </ol> </li> </ol> <p>Nextflow Tower is a more advanced interface for launching and monitoring Nextflow workflows, but you will need to move data on and off Katana yourself using the Katana Data Mover.</p> <p>Bug</p> <p>Tower is still slightly incompatible with Katana as of June 20, 2023.</p> <p>One-off setup:</p> <ol> <li>Create a Tower account at https://tower.nf.</li> <li>Navigate to https://tower.nf/tokens, create and copy an access token.</li> <li>Paste your token into the \"Katana OnDemand\" workflow utility sidebar to automatically add Katana credentials/compute and even nf-core community workflows to your Tower personal workspace.</li> </ol> <p>We currently do not support group workspaces, as sharing login credentials is against the Katana usage policy.</p>"},{"location":"guide/nextflow/#resources-advanced","title":"Resources (Advanced)","text":"<p>The default allocations from nf-core community workflows are extremely generous for most datasets - this may negatively impact your queue priority and run duration. If your input files are reasonably similar, you should consider configuring each process based on measurements.</p> <p>Optimization</p> Katana OnDemandCommand-LineNextflow Tower <p>See video in Launching a Workflow - the graphical interface interactively encourages the process described in \"Command-Line\".</p> <p>Below is an illustration of how to run nf-core/rnaseq without previous similar runs (e.g. similar or greater read depth). This is not a substitute for reading the nf-optimizer documentation/drawbacks carefully.</p> <ol> <li> <p>Limit the samples in your samplesheet, or by other means <pre><code>head -n 5 samplesheet.csv &gt; samplesheet_4.csv\n</code></pre></p> </li> <li> <p>Run Nextflow on limited samples <pre><code>export NXF_ENABLE_CACHE_INVALIDATION_ON_TASK_DIRECTIVE_CHANGE=false\nnextflow run ... --input samplesheet_4.csv\n</code></pre></p> </li> <li> <p>Generate resources.config (limited to ~120GB, 12 hours) <pre><code>nf-optimizer -m 500 120000 -t 300 43200 -o resources.config .\n</code></pre></p> </li> <li> <p>Run Nextflow on all samples <pre><code>export NXF_ENABLE_CACHE_INVALIDATION_ON_TASK_DIRECTIVE_CHANGE=false\nnextflow run ... --input samplesheet.csv -c resources.config -resume\n</code></pre></p> </li> </ol> <p>Nextflow Tower supports optimization based on a specific previous run. Click on a run in your history, navigate to \"Optimization Available\", and copy the configuration.</p> <p> Nextflow Tower built in optimization </p>"},{"location":"guide/nf_core_rnaseq/","title":"Running nf-core/RNA-Seq","text":""},{"location":"guide/nf_core_rnaseq/#introduction","title":"Introduction","text":"<p>Bulk RNA-seq involves sequencing the RNA extracted from a population of cells or tissues as a whole for the purpose of counting, while attempting to maintain proportionality with e.g. actual transcript expression. This is complicated by the need to convert to cDNA for sequencing, various biases and in eukaryotes - isoforms.</p> <p>In this guide, we will use the best-practices Nextflow workflow, nf-core/rnaseq (view official docs). You can review alternate ways to run these steps (including command-line, Tower) in the general Nextflow section - the focus of this page will be on general steps and biological parameters.</p>"},{"location":"guide/nf_core_rnaseq/#importing-your-data","title":"Importing your Data","text":"<p>The workflow accepts fastq reads, which can be downloaded using the \"Import\" step of the Genomic Workflow Utility. This will also produce a valid samplesheet.csv automatically, but you may want to set the strandedness column explicitly.</p> <p></p> The import field accepts Ramaciotti URLs, local paths, etc. <p></p> Possible to change strandedness from auto to e.g. reverse"},{"location":"guide/nf_core_rnaseq/#choosing-parameters","title":"Choosing Parameters","text":"<p>You should carefully read the full parameter list on the official docs, which may further refer you to specific tool manuals. Below is a tiny subset of frequently used parameters.</p> Parameter Summary --input Path to samplesheet. Filled for you automatically when using Genomic Workflow Utility --genome (required or see below) iGenome name, not to be confused with an actual fasta file path --fasta, --gtf (required or see above) In most cases, these should be what you use instead of an iGenome name. There is also a --gff option, more common in microbiology. It accepts a URL e.g. https://ftp.ensembl.org/../primary_assembly.fa.gz but you may want to keep local copies and supply a path, since the download is rather slow. nf-core wants to support RefGenie in future. --max-memory (optional) The default, 120GB, is more than enough for bulk RNA-Seq unless you are using HISAT, which works best with 200GB. ... ..."},{"location":"guide/nf_core_rnaseq/#running-the-workflow","title":"Running the Workflow","text":"<p>nf-core/rnaseq can typically take 4 hours for human reads, but this obviously depends greatly on read depth / size of each fastq file. See the frequently used table for more metrics.</p>"},{"location":"guide/nf_core_rnaseq/#common-errors","title":"Common Errors","text":""},{"location":"guide/nf_core_rnaseq/#1-out-of-space","title":"1. Out of space","text":"<p>e.g. <code>Failed to write...</code>, <code>File does not exist</code></p> <p>If a cryptic filesystem error occurs, always check how much space is available in the output folder first - failing to write a file or read from an expected file can imply this. </p>"},{"location":"guide/nf_core_rnaseq/#2-out-of-memory","title":"2. Out of memory","text":"<p>e.g. <code>java.lang.OutOfMemoryError: Java heap space</code></p> <p>Subtasks will be retried if they run out of memory, but the main Nextflow job will fail - this should not happen with bulk RNA-Seq, since it's usually when docker containers need to be converted to SIF.</p>"},{"location":"guide/nf_core_rnaseq/#3-missing-parameter","title":"3. Missing parameter","text":"<p><code>Genome fasta file not specified with e.g. '--fasta genome.fa' or via a detectable config file.</code></p> <p>Happens more than it should because \"fasta\" isn't a required field. For interfaces, the genome/fasta/gtf/gff fields are under \"Reference genome options\", refer to the Choosing Parameters.</p>"},{"location":"guide/nf_core_rnaseq/#support","title":"Support","text":"<p>The advantages of using a popular community workflow is that there are many people globally that can help. Contact us at ResTech for specific errors or questions. There is also a nf-core slack with channels for questions and each workflow.</p>"},{"location":"guide/RNA-Seq/circular/","title":"Circular RNA-Seq","text":""},{"location":"guide/RNA-Seq/circular/#introduction","title":"Introduction","text":"<p>Warning</p> <p>Unfortunately, <code>nf-core/circrna</code> is still considered under development and has been for some time. At least two labs at UNSW focus on circular RNAs - contact us if this is important to you.</p> <p>One common precursor to robust circular RNA studies is combining multiple detection methods. The community pipleline <code>nf-core/circrna</code> currently supports ciriquant, circexplorer2, find_circ, circrna_finder, mapsplice, dcc and segemehl, along with various QC steps. It outputs both separated and combined counts for downstream analysis. Unlike <code>nf-core/rnaseq</code>, it can also perform differential expression analysis if you provide Phenotype.csv.</p> <ol> <li>Download your data</li> </ol>"},{"location":"guide/RNA-Seq/experimental_design/","title":"Experimental Design","text":""},{"location":"guide/RNA-Seq/experimental_design/#introduction","title":"Introduction","text":"<p>The downstream analysis of most RNA-Seq studies involves some form of differential expression - as such, it is important to increase statistical power by decreasing variance using biological and technical replicates. There are no parameters for this!</p> <p>Even if you already have sequenced data and are confident in your design, terminology in bioinformatics is often re-used. This page is intended to be a concise reference for the most common concepts and terms needed to start running a workflow on Katana - see Melbourne Bioinformatic's terrific guide for a more in-depth discussion.</p>"},{"location":"guide/RNA-Seq/experimental_design/#rna-amount","title":"RNA Amount","text":"<p>The Ramaciotti Center has minimum requirements for this depending on the service. While samples certainly undergo degredation checks, you can verify this yourself using the nf-core/rnaseq optional parameter --rseqc_modules tin i.e. TIN (transcript integrity number), analogous to RIN.</p>"},{"location":"guide/RNA-Seq/experimental_design/#rrna-depletion","title":"rRNA Depletion","text":"<p>To avoid unwanted ribosomal RNA saturating your results, you must either use poly-A enrichment or specifically deplete rRNA using e.g. a kit. Poly-A enrichment is generally recommended unless studying non-coding RNAs (including circular RNAs) or your RNA is quite degraded. A higher amount of RNA is needed for rRNA depletion - furthermore, if using nf-core/rnaseq, the --remove_ribo_rna parameter can be used to filter out lingering ribosomal RNA when using this method.</p>"},{"location":"guide/RNA-Seq/experimental_design/#single-read-or-paired-end-sequencing","title":"Single-Read or Paired-End Sequencing","text":"<p>From a pure informational standpoint, paired-end sequencing is not required for differential expression, but is needed for transcription structure/splice sites. However, the known distance between read pairs is used by the alignment algorithm to produce a more accurate result. If using nf-core/rnaseq, you can define either one or two fastq file paths to implicitly indicate single/paired-end respectively.</p>"},{"location":"guide/RNA-Seq/experimental_design/#strandedness","title":"Strandedness","text":"<p>Stranded protocols/kits are not necessary to count known transcripts in a typical RNA-Seq experiment, but are needed for novel transcript discovery. If using nf-core/rnaseq, the final column in the samplesheet is used to indicate a sample's strandedness: \"unstranded\", \"forward\" or \"reverse\". In versions &gt;<code>3.12.0</code>, an additional option \"auto\" can be used to automatically infer strandeness using salmon - but it's still best to refer to your sequencing facility's exact kit when possible.</p> <p>The following table is a tiny excerpt from Griffith Lab's extensive guide on how strandedness is provided to various tools when running them individually:</p> Tool RF/fr-firststrand stranded (dUTP) FR/fr-secondstrand stranded (Ligation) Unstranded check_strandedness (output) RF/fr-firststrand FR/fr-secondstrand unstranded HISAT2 (--rna-strandness parameter) R/RF F/FR NONE HTSeq (--stranded/-s parameter) reverse yes no STAR n/a n/a n/a Salmon (--libType parameter) ISR (assuming paired-end with inward read orientation) ISF (assuming paired-end with inward read orientation) IU (assuming paired-end with inward read orientation) Example kits dUTP, NSR, NNSR, Illumina TruSeq Strand Specific Total RNA, NEBNext Ultra II Directional Ligation, Standard SOLiD, NuGEN Encore, 10X 5\u2019 scRNA data Standard Illumina, NuGEN OvationV2, SMARTer universal low input RNA kit (TaKara), GDC normalised TCGA data"},{"location":"guide/RNA-Seq/experimental_design/#multiplexing","title":"Multiplexing","text":"<p>Multiplexing can be used to reduce errors, leading to more accurate counts - whether its PCR bias using UMIs, or index hopping using UDIs. The workflow nf-core/rnaseq can be supplied with UMI barcode information if used.</p>"},{"location":"guide/RNA-Seq/experimental_design/#spike-in-sequences","title":"Spike-in Sequences","text":"<p>Spike-in controls were originally synthetic RNA sequences added for normalisation with varying results. If using nf-core/rnaseq, the parameter --additional_fasta was introduced for this purpose, but also represents an elegant way to append any custom sequence without keeping track of large locally modified reference genomes.</p>"},{"location":"guide/RNA-Seq/single_cell/","title":"Single-Cell RNA-Seq","text":""},{"location":"guide/RNA-Seq/single_cell/#introduction","title":"Introduction","text":"<p>10x Genomics single-cell RNA-seq, unlike bulk RNA-Seq, adds additional barcode information combinatorally in order to group counts by the actual cells they originated from.</p> <ol> <li>Download your data</li> </ol>"}]}